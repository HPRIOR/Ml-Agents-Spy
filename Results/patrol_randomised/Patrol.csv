Steps,Policy/Extrinsic Value Estimate,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Policy/Entropy,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
60000,0.048730697,3.2564723e-05,0.06844849,0.00029864095,0.19954698,0.009954744,2.6135168,643.0,0.24062498880084604,0.24062498880084604,1.0
90000,0.032996126,4.6683086e-05,0.06622433,0.00029775247,0.1992508,0.009925157,2.5213578,1999.0,0.7688815490538744,0.7688815490538744,1.0
120000,0.047304705,0.00010511638,0.073591135,0.00029686175,0.19895388,0.009895497,2.2700312,None,None,None,1.0
150000,0.04946232,8.7307344e-05,0.07087329,0.0002959577,0.19865257,0.009865391,1.9091973,966.0,0.6127777478347222,0.6127777478347222,1.0
180000,0.09512978,8.989512e-05,0.06750653,0.00029505297,0.198351,0.009835265,1.5702968,1999.0,1.5924998950855485,1.5924998950855485,1.0
210000,0.14699185,0.000110292975,0.074653745,0.00029415506,0.19805168,0.009805363,1.1547691,1793.2068965517242,2.8593100302949033,2.8593100302949033,1.0
